{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['JAX_PLATFORMS'] = 'cpu'\n",
        "NUM_DEVICES = 8\n",
        "os.environ['XLA_FLAGS'] = f\"--xla_force_host_platform_device_count={NUM_DEVICES}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-08-18 22:20:29.836581: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-08-18 22:20:29.846405: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-08-18 22:20:29.849142: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-08-18 22:20:30.468782: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[CpuDevice(id=0),\n",
              " CpuDevice(id=1),\n",
              " CpuDevice(id=2),\n",
              " CpuDevice(id=3),\n",
              " CpuDevice(id=4),\n",
              " CpuDevice(id=5),\n",
              " CpuDevice(id=6),\n",
              " CpuDevice(id=7)]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import time\n",
        "from jax import jit, random, value_and_grad, vmap\n",
        "from jax.nn import logsumexp, one_hot, swish\n",
        "from jax.sharding import PositionalSharding\n",
        "\n",
        "jax.devices()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1724044831.170295   19039 cuda_executor.cc:1001] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
            "Your kernel may have been built without NUMA support.\n",
            "2024-08-18 22:20:31.194410: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2343] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ]
        }
      ],
      "source": [
        "data, info = tfds.load(name=\"mnist\",\n",
        "                       data_dir='/tmp/tfds',\n",
        "                       as_supervised=True,\n",
        "                       with_info=True)\n",
        "data_train = data['train']\n",
        "data_test  = data['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "BATCH_SIZE  = 32\n",
        "HEIGHT = 28\n",
        "WIDTH  = 28\n",
        "CHANNELS = 1\n",
        "NUM_PIXELS = HEIGHT * WIDTH * CHANNELS\n",
        "NUM_LABELS = info.features['label'].num_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "OwXDzEbT1j61"
      },
      "outputs": [],
      "source": [
        "def preprocess(img, label):\n",
        "  return (tf.cast(img, tf.float32)/255.0), label\n",
        "\n",
        "train_data = tfds.as_numpy(data_train.map(preprocess).batch(BATCH_SIZE).prefetch(1))\n",
        "test_data  = tfds.as_numpy(data_test.map(preprocess).batch(BATCH_SIZE).prefetch(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def init_network_params(sizes, key=random.PRNGKey(0), scale=1e-2):\n",
        "\n",
        "  def random_layer_params(m, n, key, scale=1e-2):\n",
        "    w_key, b_key = random.split(key)\n",
        "    return scale * random.normal(w_key, (n, m)), scale * random.normal(b_key, (n,))\n",
        "\n",
        "  keys = random.split(key, len(sizes))\n",
        "  return [random_layer_params(m, n, k, scale) for m, n, k in zip(sizes[:-1], sizes[1:], keys)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict(params, image):\n",
        "  activations = image\n",
        "  for w, b in params[:-1]:\n",
        "    outputs = jnp.dot(w, activations) + b\n",
        "    activations = swish(outputs)\n",
        "\n",
        "  final_w, final_b = params[-1]\n",
        "  logits = jnp.dot(final_w, activations) + final_b\n",
        "  return logits\n",
        "\n",
        "batched_predict = vmap(predict, in_axes=(None, 0))\n",
        "\n",
        "def loss(params, images, targets):\n",
        "  logits = batched_predict(params, images)\n",
        "  log_preds = logits - jnp.expand_dims(logsumexp(logits, axis=1), 1)\n",
        "  return -jnp.mean(targets*log_preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "MjDtmztL1925"
      },
      "outputs": [],
      "source": [
        "@jit\n",
        "def batch_accuracy(params, images, targets):\n",
        "  images = jnp.reshape(images, (len(images), NUM_PIXELS))\n",
        "  predicted_class = jnp.argmax(batched_predict(params, images), axis=1)\n",
        "  return jnp.mean(predicted_class == targets)\n",
        "\n",
        "def accuracy(params, data):\n",
        "  accs = []\n",
        "  for images, targets in data:\n",
        "    accs.append(batch_accuracy(params, images, targets))\n",
        "  return jnp.mean(jnp.array(accs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "INIT_LR = 1.0\n",
        "DECAY_RATE = 0.95\n",
        "DECAY_STEPS = 5\n",
        "\n",
        "@jit\n",
        "def update(params, x, y, epoch_number):\n",
        "  loss_value, grads = value_and_grad(loss)(params, x, y)\n",
        "  lr = INIT_LR * DECAY_RATE ** (epoch_number / DECAY_STEPS)\n",
        "  return [(w - lr * dw, b - lr * db)\n",
        "          for (w, b), (dw, db) in zip(params, grads)], loss_value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### 8-way data parallelism"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 in 10.08 sec\n",
            "Training set loss 0.04564366862177849\n",
            "Training set accuracy 0.9270833730697632\n",
            "Test set accuracy 0.9273162484169006\n",
            "Epoch 1 in 9.17 sec\n",
            "Training set loss 0.021921737119555473\n",
            "Training set accuracy 0.9524999856948853\n",
            "Test set accuracy 0.9517771601676941\n",
            "Epoch 2 in 9.31 sec\n",
            "Training set loss 0.015344643034040928\n",
            "Training set accuracy 0.9641333222389221\n",
            "Test set accuracy 0.9603633880615234\n",
            "Epoch 3 in 9.35 sec\n",
            "Training set loss 0.011921508237719536\n",
            "Training set accuracy 0.9709666967391968\n",
            "Test set accuracy 0.9664536714553833\n",
            "Epoch 4 in 9.42 sec\n",
            "Training set loss 0.009811367839574814\n",
            "Training set accuracy 0.9756333231925964\n",
            "Test set accuracy 0.9702475666999817\n"
          ]
        }
      ],
      "source": [
        "LAYER_SIZES = [HEIGHT * WIDTH, 512, 10]\n",
        "PARAM_SCALE = 0.01\n",
        "params = init_network_params(LAYER_SIZES, random.PRNGKey(0), scale=PARAM_SCALE)\n",
        "\n",
        "sharding = PositionalSharding(jax.devices()).reshape(8, 1)\n",
        "\n",
        "NUM_EPOCHS  = 5\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  start_time = time.time()\n",
        "  losses = []\n",
        "  for x, y in train_data:\n",
        "    x = jnp.reshape(x, (len(x), NUM_PIXELS))\n",
        "    y = one_hot(y, NUM_LABELS)\n",
        "    x = jax.device_put(x, sharding)\n",
        "    y = jax.device_put(y, sharding)\n",
        "    params = jax.device_put(params, sharding.replicate())\n",
        "    params, loss_value = update(params, x, y, epoch)\n",
        "    losses.append(loss_value)\n",
        "  epoch_time = time.time() - start_time\n",
        "\n",
        "  train_acc = accuracy(params, train_data)\n",
        "  test_acc = accuracy(params, test_data)\n",
        "  print(\"Epoch {} in {:0.2f} sec\".format(epoch, epoch_time))\n",
        "  print(\"Training set loss {}\".format(jnp.mean(jnp.array(losses))))\n",
        "  print(\"Training set accuracy {}\".format(train_acc))\n",
        "  print(\"Test set accuracy {}\".format(test_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alhuQ3jN3Zp8"
      },
      "source": [
        "#### 4-way data parallelism, 2-way tensor parallelism"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jyVcAxPC3mGG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 in 5.52 sec\n",
            "Training set loss 0.04564366862177849\n",
            "Training set accuracy 0.9270833730697632\n",
            "Test set accuracy 0.9273162484169006\n",
            "Epoch 1 in 5.55 sec\n",
            "Training set loss 0.021921737119555473\n",
            "Training set accuracy 0.9524999856948853\n",
            "Test set accuracy 0.9517771601676941\n",
            "Epoch 2 in 5.41 sec\n",
            "Training set loss 0.015344643034040928\n",
            "Training set accuracy 0.9641333222389221\n",
            "Test set accuracy 0.9603633880615234\n",
            "Epoch 3 in 5.27 sec\n",
            "Training set loss 0.01192150916904211\n",
            "Training set accuracy 0.9709666967391968\n",
            "Test set accuracy 0.9664536714553833\n",
            "Epoch 4 in 5.39 sec\n",
            "Training set loss 0.009811367839574814\n",
            "Training set accuracy 0.9756333231925964\n",
            "Test set accuracy 0.9702475666999817\n"
          ]
        }
      ],
      "source": [
        "#LAYER_SIZES = [HEIGHT * WIDTH, 10000, 10000, 10]\n",
        "params = init_network_params(LAYER_SIZES, random.PRNGKey(0), scale=PARAM_SCALE)\n",
        "\n",
        "sharding = PositionalSharding(jax.devices()).reshape(4, 2)\n",
        "\n",
        "sharded_params = []\n",
        "for i,(w,b) in enumerate(params):\n",
        "  if i==(len(params)-1):\n",
        "    w = jax.device_put(w, sharding.replicate())\n",
        "    b = jax.device_put(b, sharding.replicate())\n",
        "  else:\n",
        "    w = jax.device_put(w, sharding.replicate(0))\n",
        "    b = jax.device_put(b, sharding.replicate())\n",
        "  sharded_params.append((w,b))\n",
        "  #jax.debug.visualize_array_sharding(w)\n",
        "  #jax.debug.visualize_array_sharding(b)\n",
        "\n",
        "params = sharded_params\n",
        "\n",
        "NUM_EPOCHS  = 5\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  start_time = time.time()\n",
        "  losses = []\n",
        "  for x, y in train_data:\n",
        "    x = jnp.reshape(x, (len(x), NUM_PIXELS))\n",
        "    y = one_hot(y, NUM_LABELS)\n",
        "    x = jax.device_put(x, sharding.replicate(1))\n",
        "    y = jax.device_put(y, sharding.replicate(1))\n",
        "    params, loss_value = update(params, x, y, epoch)\n",
        "    losses.append(jnp.sum(loss_value))\n",
        "  epoch_time = time.time() - start_time\n",
        "\n",
        "  train_acc = accuracy(params, train_data)\n",
        "  test_acc = accuracy(params, test_data)\n",
        "  print(\"Epoch {} in {:0.2f} sec\".format(epoch, epoch_time))\n",
        "  print(\"Training set loss {}\".format(jnp.mean(jnp.array(losses))))\n",
        "  print(\"Training set accuracy {}\".format(train_acc))\n",
        "  print(\"Test set accuracy {}\".format(test_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
